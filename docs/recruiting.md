---
title: Get Involved
permalink: /recruiting/
---

# Get Involved

## Why this matters

In 2023, a broad coalition of AI researchers and lab leaders signed a plain, one-sentence warning:

> "Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war."

Source: Center for AI Safety; "Statement on AI Risk" (2023): https://safe.ai/work/press-release-ai-risk

[I. J. Good](https://en.wikipedia.org/wiki/I._J._Good), one of the earliest voices to describe an "intelligence explosion," put it in a single sentence:

> "Thus the first ultraintelligent machine is the last invention that man need ever make, **provided that the machine is docile enough to tell us how to keep it under control**."

---

## You can contribute at any effort level

This project has seven outreach modes. Pick the one that fits your situation.

| Mode | What it takes |
|------|--------------|
| [Individual Advocacy]({{ "/playbooks/individual-advocacy/" | relative_url }}) | A conversation |
| [Static Presence]({{ "/playbooks/static-presence/" | relative_url }}) | 1–2 hours to place materials |
| [Signal Actions]({{ "/playbooks/signal-actions/" | relative_url }}) | 15–30 minutes with a sign |
| [Micro-Gatherings]({{ "/playbooks/micro-gatherings/" | relative_url }}) | 1–2 hours to host a discussion |
| [Interactive Booths]({{ "/playbooks/interactive-booths/" | relative_url }}) | Half-day at an event (City Lead role) |
| [Institutional Touchpoints]({{ "/playbooks/institutional-touchpoints/" | relative_url }}) | Variable |
| [Digital Amplification]({{ "/playbooks/digital-amplification/" | relative_url }}) | Async |

---

## You do not have to be convinced about "existential risk"

Many people do not see AI as an existential threat. Some are unsure. Some disagree strongly. Volunteers do not need to "win" that argument.

The purpose of outreach is to raise awareness, help people form informed views at their own pace, and capture real questions so messaging improves.

If your posture is curiosity, humility, and respect, you are a fit.

---

## Why local outreach matters

Most communities do not have a visible, approachable entry point for AI risk and governance questions. Local outreach helps because it:
- Reaches people who will never seek out AI safety topics on their own
- Creates low-pressure first exposure
- Builds local legitimacy ("normal people are talking about this")
- Creates a feedback loop for better messaging

---

## What volunteers do not do (all modes)

- Do not debate people; keep it informational
- Do not endorse candidates or parties
- Do not collect sensitive personal data
- Do not improvise statistics or claims

---

## Outreach posture (all modes)

Default opener:
> "I'm sharing information about AI safety policy — it's a nonpartisan topic that doesn't get a lot of local coverage."

If someone is skeptical:
> "That's reasonable. I'm not here to convince you — just to make sure people know the issue exists."

If someone wants to debate:
> "We try to keep this informational. There's a good short overview at the link if you want to look at it on your own time."

---

## How to get involved

**For any mode:** Read the relevant playbook and start.

**For Interactive Booths (City Lead role):**
1. Read the [pitch]({{ "/pitch/" | relative_url }}) and [sponsoring]({{ "/sponsoring/" | relative_url }}) pages
2. Review the [After-Action Report template]({{ "/aar/" | relative_url }})
3. Open an issue titled: **City Pilot Request: \<City, State\>**

Include which mode(s) you want to run, the event(s) you want to target, your commitment window, and confirmation you will submit AARs.
